{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.datasets import load_diabetes\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "цей спосіб вибору змінних релевантний тільки для лінійної та логістичної регресії"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_insignificant_features_reg(X_train, y_train, significance_level=0.05):\n",
        "    X_train_sm = sm.add_constant(X_train)\n",
        "    while True:\n",
        "        model = sm.OLS(y_train, X_train_sm).fit()\n",
        "        p_values = model.pvalues\n",
        "        max_p_value = p_values.max()\n",
        "        \n",
        "        if max_p_value < significance_level:\n",
        "            break\n",
        "        \n",
        "        feature_to_remove = p_values.idxmax()\n",
        "        X_train_sm = X_train_sm.drop(columns=[feature_to_remove])\n",
        "        print(f\"Видалено фічу: {feature_to_remove} (p-value = {max_p_value:.4f})\")\n",
        "    \n",
        "    return X_train_sm.drop(columns=['const'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_p_values(X_train, y_train):\n",
        "    X_train_sm = sm.add_constant(X_train)\n",
        "    model = sm.OLS(y_train, X_train_sm).fit()\n",
        "    return model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "diabetes = load_diabetes()\n",
        "X_train = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "y_train = pd.Series(diabetes.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.518</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.507</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.27</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 25 Feb 2025</td> <th>  Prob (F-statistic):</th> <td>3.83e-62</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:51:25</td>     <th>  Log-Likelihood:    </th> <td> -2386.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   442</td>      <th>  AIC:               </th> <td>   4794.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   431</td>      <th>  BIC:               </th> <td>   4839.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  152.1335</td> <td>    2.576</td> <td>   59.061</td> <td> 0.000</td> <td>  147.071</td> <td>  157.196</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>age</th>   <td>  -10.0099</td> <td>   59.749</td> <td>   -0.168</td> <td> 0.867</td> <td> -127.446</td> <td>  107.426</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sex</th>   <td> -239.8156</td> <td>   61.222</td> <td>   -3.917</td> <td> 0.000</td> <td> -360.147</td> <td> -119.484</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>bmi</th>   <td>  519.8459</td> <td>   66.533</td> <td>    7.813</td> <td> 0.000</td> <td>  389.076</td> <td>  650.616</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>bp</th>    <td>  324.3846</td> <td>   65.422</td> <td>    4.958</td> <td> 0.000</td> <td>  195.799</td> <td>  452.970</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s1</th>    <td> -792.1756</td> <td>  416.680</td> <td>   -1.901</td> <td> 0.058</td> <td>-1611.153</td> <td>   26.802</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s2</th>    <td>  476.7390</td> <td>  339.030</td> <td>    1.406</td> <td> 0.160</td> <td> -189.620</td> <td> 1143.098</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s3</th>    <td>  101.0433</td> <td>  212.531</td> <td>    0.475</td> <td> 0.635</td> <td> -316.684</td> <td>  518.770</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s4</th>    <td>  177.0632</td> <td>  161.476</td> <td>    1.097</td> <td> 0.273</td> <td> -140.315</td> <td>  494.441</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s5</th>    <td>  751.2737</td> <td>  171.900</td> <td>    4.370</td> <td> 0.000</td> <td>  413.407</td> <td> 1089.140</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>s6</th>    <td>   67.6267</td> <td>   65.984</td> <td>    1.025</td> <td> 0.306</td> <td>  -62.064</td> <td>  197.318</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.506</td> <th>  Durbin-Watson:     </th> <td>   2.029</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.471</td> <th>  Jarque-Bera (JB):  </th> <td>   1.404</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.017</td> <th>  Prob(JB):          </th> <td>   0.496</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.726</td> <th>  Cond. No.          </th> <td>    227.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": [
              "\\begin{center}\n",
              "\\begin{tabular}{lclc}\n",
              "\\toprule\n",
              "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.518   \\\\\n",
              "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.507   \\\\\n",
              "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     46.27   \\\\\n",
              "\\textbf{Date:}             & Tue, 25 Feb 2025 & \\textbf{  Prob (F-statistic):} &  3.83e-62   \\\\\n",
              "\\textbf{Time:}             &     17:51:25     & \\textbf{  Log-Likelihood:    } &   -2386.0   \\\\\n",
              "\\textbf{No. Observations:} &         442      & \\textbf{  AIC:               } &     4794.   \\\\\n",
              "\\textbf{Df Residuals:}     &         431      & \\textbf{  BIC:               } &     4839.   \\\\\n",
              "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
              "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
              "\\bottomrule\n",
              "\\end{tabular}\n",
              "\\begin{tabular}{lcccccc}\n",
              "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
              "\\midrule\n",
              "\\textbf{const} &     152.1335  &        2.576     &    59.061  &         0.000        &      147.071    &      157.196     \\\\\n",
              "\\textbf{age}   &     -10.0099  &       59.749     &    -0.168  &         0.867        &     -127.446    &      107.426     \\\\\n",
              "\\textbf{sex}   &    -239.8156  &       61.222     &    -3.917  &         0.000        &     -360.147    &     -119.484     \\\\\n",
              "\\textbf{bmi}   &     519.8459  &       66.533     &     7.813  &         0.000        &      389.076    &      650.616     \\\\\n",
              "\\textbf{bp}    &     324.3846  &       65.422     &     4.958  &         0.000        &      195.799    &      452.970     \\\\\n",
              "\\textbf{s1}    &    -792.1756  &      416.680     &    -1.901  &         0.058        &    -1611.153    &       26.802     \\\\\n",
              "\\textbf{s2}    &     476.7390  &      339.030     &     1.406  &         0.160        &     -189.620    &     1143.098     \\\\\n",
              "\\textbf{s3}    &     101.0433  &      212.531     &     0.475  &         0.635        &     -316.684    &      518.770     \\\\\n",
              "\\textbf{s4}    &     177.0632  &      161.476     &     1.097  &         0.273        &     -140.315    &      494.441     \\\\\n",
              "\\textbf{s5}    &     751.2737  &      171.900     &     4.370  &         0.000        &      413.407    &     1089.140     \\\\\n",
              "\\textbf{s6}    &      67.6267  &       65.984     &     1.025  &         0.306        &      -62.064    &      197.318     \\\\\n",
              "\\bottomrule\n",
              "\\end{tabular}\n",
              "\\begin{tabular}{lclc}\n",
              "\\textbf{Omnibus:}       &  1.506 & \\textbf{  Durbin-Watson:     } &    2.029  \\\\\n",
              "\\textbf{Prob(Omnibus):} &  0.471 & \\textbf{  Jarque-Bera (JB):  } &    1.404  \\\\\n",
              "\\textbf{Skew:}          &  0.017 & \\textbf{  Prob(JB):          } &    0.496  \\\\\n",
              "\\textbf{Kurtosis:}      &  2.726 & \\textbf{  Cond. No.          } &     227.  \\\\\n",
              "\\bottomrule\n",
              "\\end{tabular}\n",
              "%\\caption{OLS Regression Results}\n",
              "\\end{center}\n",
              "\n",
              "Notes: \\newline\n",
              " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.518\n",
              "Model:                            OLS   Adj. R-squared:                  0.507\n",
              "Method:                 Least Squares   F-statistic:                     46.27\n",
              "Date:                Tue, 25 Feb 2025   Prob (F-statistic):           3.83e-62\n",
              "Time:                        17:51:25   Log-Likelihood:                -2386.0\n",
              "No. Observations:                 442   AIC:                             4794.\n",
              "Df Residuals:                     431   BIC:                             4839.\n",
              "Df Model:                          10                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        152.1335      2.576     59.061      0.000     147.071     157.196\n",
              "age          -10.0099     59.749     -0.168      0.867    -127.446     107.426\n",
              "sex         -239.8156     61.222     -3.917      0.000    -360.147    -119.484\n",
              "bmi          519.8459     66.533      7.813      0.000     389.076     650.616\n",
              "bp           324.3846     65.422      4.958      0.000     195.799     452.970\n",
              "s1          -792.1756    416.680     -1.901      0.058   -1611.153      26.802\n",
              "s2           476.7390    339.030      1.406      0.160    -189.620    1143.098\n",
              "s3           101.0433    212.531      0.475      0.635    -316.684     518.770\n",
              "s4           177.0632    161.476      1.097      0.273    -140.315     494.441\n",
              "s5           751.2737    171.900      4.370      0.000     413.407    1089.140\n",
              "s6            67.6267     65.984      1.025      0.306     -62.064     197.318\n",
              "==============================================================================\n",
              "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
              "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
              "Skew:                           0.017   Prob(JB):                        0.496\n",
              "Kurtosis:                       2.726   Cond. No.                         227.\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_p_values(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загальні метрики моделі\n",
        "\n",
        "* Dep. Variable (Залежна змінна): y — це цільова змінна, яку ми намагаємося передбачити.\n",
        "* R-squared (Коефіцієнт детермінації): 0.518\n",
        "* Означає, що модель пояснює 51.8% варіації залежної змінної.\n",
        "* Adj. R-squared (Скоригований R²): 0.507\n",
        "    Бере до уваги кількість предикторів і штрафує за зайві змінні. Оскільки скоригований R² трохи нижчий за звичайний R², деякі фічі можуть бути зайвими.\n",
        "* F-statistic: 46.27\n",
        "    Оцінює, наскільки модель значуща загалом.\n",
        "* Prob (F-statistic): 3.83e-62\n",
        "    Дуже мале значення (≈ 0), що означає, що хоча б одна незалежна змінна справді впливає на y.\n",
        "\n",
        "Інформація про вибірку\n",
        "\n",
        "* No. Observations (Кількість спостережень): 442\n",
        "* Df Model (Ступені свободи моделі): 10 (кількість фіч)\n",
        "* Df Residuals (Ступені свободи залишків): 431 (442 - 10 - 1)\n",
        "* Log-Likelihood: -2386.0\n",
        "    Чим більше (менш негативне) значення, тим краще модель підходить до даних.\n",
        "* AIC (Akaike Information Criterion): 4794\n",
        "* BIC (Bayesian Information Criterion): 4839\n",
        "    Чим менше AIC/BIC, тим краще модель. Їх можна використовувати для порівняння моделей.\n",
        "\n",
        "* coef (β) — коефіцієнти регресії. Покажуть, як зміна фічі на 1 одиницю змінює y.\n",
        "* Std Err — стандартна помилка коефіцієнта.\n",
        "* t — t-статистика (чим більше, тим значущіша змінна).\n",
        "* P>|t| — p-value. Якщо p-value < 0.05, то змінна значуща.\n",
        "* 95% CI — довірчий інтервал (якщо включає 0, змінна може бути незначущою).\n",
        "\n",
        "Аналіз змінних\n",
        "Значущі змінні (p-value < 0.05):\n",
        "sex, bmi, bp, s5\n",
        "\n",
        "Майже значуща (p = 0.058):\n",
        "s1\n",
        "\n",
        "Незначущі:\n",
        "\n",
        "age, s2, s3, s4, s6\n",
        "\n",
        "→ `Їх можна спробувати видалити`\n",
        "\n",
        "Додаткові діагностичні тести\n",
        " - Durbin-Watson: 2.029\n",
        "Близько до 2 → відсутня серйозна автокореляція.\n",
        " - Omnibus / Prob(Omnibus): 1.506 / 0.471\n",
        "Тест на нормальність залишків (p > 0.05 → нормальний розподіл).\n",
        " - Jarque-Bera (JB) / Prob(JB): 1.404 / 0.496\n",
        "Також перевіряє нормальність (p > 0.05 → залишки нормальні).\n",
        " - Skew (Асиметрія): 0.017\n",
        "Майже симетричний розподіл.\n",
        " - Kurtosis (Ексцес): 2.726\n",
        "Близько до 3 → нормальний розподіл."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Видалено фічу: age (p-value = 0.8670)\n",
            "Видалено фічу: s3 (p-value = 0.6386)\n",
            "Видалено фічу: s6 (p-value = 0.3040)\n",
            "Видалено фічу: s4 (p-value = 0.2619)\n"
          ]
        }
      ],
      "source": [
        "X_train_cleaned = remove_insignificant_features_reg(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>0.019907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>-0.068332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005670</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>0.002861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>0.022688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>-0.031988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>0.031193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.018114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017293</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.046883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>0.044529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081413</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>-0.004222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          sex       bmi        bp        s1        s2        s5\n",
              "0    0.050680  0.061696  0.021872 -0.044223 -0.034821  0.019907\n",
              "1   -0.044642 -0.051474 -0.026328 -0.008449 -0.019163 -0.068332\n",
              "2    0.050680  0.044451 -0.005670 -0.045599 -0.034194  0.002861\n",
              "3   -0.044642 -0.011595 -0.036656  0.012191  0.024991  0.022688\n",
              "4   -0.044642 -0.036385  0.021872  0.003935  0.015596 -0.031988\n",
              "..        ...       ...       ...       ...       ...       ...\n",
              "437  0.050680  0.019662  0.059744 -0.005697 -0.002566  0.031193\n",
              "438  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.018114\n",
              "439  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.046883\n",
              "440 -0.044642  0.039062  0.001215  0.016318  0.015283  0.044529\n",
              "441 -0.044642 -0.073030 -0.081413  0.083740  0.027809 -0.004222\n",
              "\n",
              "[442 rows x 6 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>...</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>9.029</td>\n",
              "      <td>17.33</td>\n",
              "      <td>0.14130</td>\n",
              "      <td>0.31300</td>\n",
              "      <td>0.04375</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>1.1940</td>\n",
              "      <td>1.8850</td>\n",
              "      <td>17.67</td>\n",
              "      <td>0.086060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033220</td>\n",
              "      <td>10.310</td>\n",
              "      <td>22.65</td>\n",
              "      <td>65.50</td>\n",
              "      <td>0.14820</td>\n",
              "      <td>0.43650</td>\n",
              "      <td>1.25200</td>\n",
              "      <td>0.17500</td>\n",
              "      <td>0.4228</td>\n",
              "      <td>0.11750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>21.090</td>\n",
              "      <td>26.57</td>\n",
              "      <td>0.28320</td>\n",
              "      <td>0.24870</td>\n",
              "      <td>0.14960</td>\n",
              "      <td>0.2395</td>\n",
              "      <td>0.7629</td>\n",
              "      <td>4.4140</td>\n",
              "      <td>81.46</td>\n",
              "      <td>0.047590</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015670</td>\n",
              "      <td>26.680</td>\n",
              "      <td>33.48</td>\n",
              "      <td>176.50</td>\n",
              "      <td>0.14910</td>\n",
              "      <td>0.75840</td>\n",
              "      <td>0.67800</td>\n",
              "      <td>0.29030</td>\n",
              "      <td>0.4098</td>\n",
              "      <td>0.12840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>9.173</td>\n",
              "      <td>13.86</td>\n",
              "      <td>0.08751</td>\n",
              "      <td>0.05988</td>\n",
              "      <td>0.02180</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>2.2650</td>\n",
              "      <td>2.6080</td>\n",
              "      <td>23.52</td>\n",
              "      <td>0.039380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015600</td>\n",
              "      <td>10.010</td>\n",
              "      <td>19.23</td>\n",
              "      <td>65.59</td>\n",
              "      <td>0.09836</td>\n",
              "      <td>0.16780</td>\n",
              "      <td>0.13970</td>\n",
              "      <td>0.05087</td>\n",
              "      <td>0.3282</td>\n",
              "      <td>0.08490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>10.650</td>\n",
              "      <td>25.22</td>\n",
              "      <td>0.07234</td>\n",
              "      <td>0.02379</td>\n",
              "      <td>0.01615</td>\n",
              "      <td>0.1897</td>\n",
              "      <td>1.4930</td>\n",
              "      <td>1.4970</td>\n",
              "      <td>16.64</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>12.250</td>\n",
              "      <td>35.19</td>\n",
              "      <td>77.98</td>\n",
              "      <td>0.14990</td>\n",
              "      <td>0.13980</td>\n",
              "      <td>0.11250</td>\n",
              "      <td>0.06136</td>\n",
              "      <td>0.3409</td>\n",
              "      <td>0.08147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>10.170</td>\n",
              "      <td>14.88</td>\n",
              "      <td>0.08061</td>\n",
              "      <td>0.01084</td>\n",
              "      <td>0.01290</td>\n",
              "      <td>0.2743</td>\n",
              "      <td>1.4410</td>\n",
              "      <td>3.3120</td>\n",
              "      <td>34.62</td>\n",
              "      <td>0.010990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008193</td>\n",
              "      <td>11.020</td>\n",
              "      <td>17.45</td>\n",
              "      <td>69.86</td>\n",
              "      <td>0.12750</td>\n",
              "      <td>0.09866</td>\n",
              "      <td>0.02168</td>\n",
              "      <td>0.02579</td>\n",
              "      <td>0.3557</td>\n",
              "      <td>0.08020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>8.888</td>\n",
              "      <td>14.64</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.08606</td>\n",
              "      <td>0.02872</td>\n",
              "      <td>0.1902</td>\n",
              "      <td>0.8522</td>\n",
              "      <td>3.1680</td>\n",
              "      <td>25.44</td>\n",
              "      <td>0.093680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017660</td>\n",
              "      <td>9.733</td>\n",
              "      <td>15.67</td>\n",
              "      <td>62.56</td>\n",
              "      <td>0.12070</td>\n",
              "      <td>0.24360</td>\n",
              "      <td>0.14340</td>\n",
              "      <td>0.04786</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>0.10840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>11.640</td>\n",
              "      <td>18.33</td>\n",
              "      <td>0.10170</td>\n",
              "      <td>0.07070</td>\n",
              "      <td>0.03485</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>1.6570</td>\n",
              "      <td>2.1550</td>\n",
              "      <td>20.62</td>\n",
              "      <td>0.023100</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013980</td>\n",
              "      <td>13.140</td>\n",
              "      <td>29.26</td>\n",
              "      <td>85.51</td>\n",
              "      <td>0.16880</td>\n",
              "      <td>0.26600</td>\n",
              "      <td>0.28730</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.2806</td>\n",
              "      <td>0.09097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>14.290</td>\n",
              "      <td>16.82</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.00725</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.1508</td>\n",
              "      <td>0.7198</td>\n",
              "      <td>0.8439</td>\n",
              "      <td>10.77</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003608</td>\n",
              "      <td>14.910</td>\n",
              "      <td>20.65</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.08567</td>\n",
              "      <td>0.05036</td>\n",
              "      <td>0.03866</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>0.2458</td>\n",
              "      <td>0.06120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>13.980</td>\n",
              "      <td>19.62</td>\n",
              "      <td>0.11330</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>0.1669</td>\n",
              "      <td>0.9533</td>\n",
              "      <td>1.6020</td>\n",
              "      <td>18.85</td>\n",
              "      <td>0.017910</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009567</td>\n",
              "      <td>17.040</td>\n",
              "      <td>30.80</td>\n",
              "      <td>113.90</td>\n",
              "      <td>0.16130</td>\n",
              "      <td>0.35680</td>\n",
              "      <td>0.40690</td>\n",
              "      <td>0.18270</td>\n",
              "      <td>0.3179</td>\n",
              "      <td>0.10550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>12.180</td>\n",
              "      <td>20.52</td>\n",
              "      <td>0.04038</td>\n",
              "      <td>0.02383</td>\n",
              "      <td>0.01770</td>\n",
              "      <td>0.1739</td>\n",
              "      <td>1.5710</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>14.68</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006797</td>\n",
              "      <td>13.340</td>\n",
              "      <td>32.84</td>\n",
              "      <td>84.58</td>\n",
              "      <td>0.11230</td>\n",
              "      <td>0.08862</td>\n",
              "      <td>0.11450</td>\n",
              "      <td>0.07431</td>\n",
              "      <td>0.2694</td>\n",
              "      <td>0.06878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  mean compactness  mean concavity  \\\n",
              "68         9.029         17.33           0.14130         0.31300   \n",
              "181       21.090         26.57           0.28320         0.24870   \n",
              "63         9.173         13.86           0.08751         0.05988   \n",
              "248       10.650         25.22           0.07234         0.02379   \n",
              "60        10.170         14.88           0.08061         0.01084   \n",
              "..           ...           ...               ...             ...   \n",
              "71         8.888         14.64           0.15310         0.08606   \n",
              "106       11.640         18.33           0.10170         0.07070   \n",
              "270       14.290         16.82           0.02675         0.00725   \n",
              "435       13.980         19.62           0.11330         0.11260   \n",
              "102       12.180         20.52           0.04038         0.02383   \n",
              "\n",
              "     mean concave points  mean symmetry  texture error  perimeter error  \\\n",
              "68               0.04375         0.2111         1.1940           1.8850   \n",
              "181              0.14960         0.2395         0.7629           4.4140   \n",
              "63               0.02180         0.2341         2.2650           2.6080   \n",
              "248              0.01615         0.1897         1.4930           1.4970   \n",
              "60               0.01290         0.2743         1.4410           3.3120   \n",
              "..                   ...            ...            ...              ...   \n",
              "71               0.02872         0.1902         0.8522           3.1680   \n",
              "106              0.03485         0.1801         1.6570           2.1550   \n",
              "270              0.00625         0.1508         0.7198           0.8439   \n",
              "435              0.06463         0.1669         0.9533           1.6020   \n",
              "102              0.01770         0.1739         1.5710           1.1830   \n",
              "\n",
              "     area error  compactness error  ...  concave points error  worst radius  \\\n",
              "68        17.67           0.086060  ...              0.033220        10.310   \n",
              "181       81.46           0.047590  ...              0.015670        26.680   \n",
              "63        23.52           0.039380  ...              0.015600        10.010   \n",
              "248       16.64           0.010350  ...              0.006245        12.250   \n",
              "60        34.62           0.010990  ...              0.008193        11.020   \n",
              "..          ...                ...  ...                   ...           ...   \n",
              "71        25.44           0.093680  ...              0.017660         9.733   \n",
              "106       20.62           0.023100  ...              0.013980        13.140   \n",
              "270       10.77           0.003710  ...              0.003608        14.910   \n",
              "435       18.85           0.017910  ...              0.009567        17.040   \n",
              "102       14.68           0.006098  ...              0.006797        13.340   \n",
              "\n",
              "     worst texture  worst perimeter  worst smoothness  worst compactness  \\\n",
              "68           22.65            65.50           0.14820            0.43650   \n",
              "181          33.48           176.50           0.14910            0.75840   \n",
              "63           19.23            65.59           0.09836            0.16780   \n",
              "248          35.19            77.98           0.14990            0.13980   \n",
              "60           17.45            69.86           0.12750            0.09866   \n",
              "..             ...              ...               ...                ...   \n",
              "71           15.67            62.56           0.12070            0.24360   \n",
              "106          29.26            85.51           0.16880            0.26600   \n",
              "270          20.65            94.44           0.08567            0.05036   \n",
              "435          30.80           113.90           0.16130            0.35680   \n",
              "102          32.84            84.58           0.11230            0.08862   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "68           1.25200               0.17500          0.4228   \n",
              "181          0.67800               0.29030          0.4098   \n",
              "63           0.13970               0.05087          0.3282   \n",
              "248          0.11250               0.06136          0.3409   \n",
              "60           0.02168               0.02579          0.3557   \n",
              "..               ...                   ...             ...   \n",
              "71           0.14340               0.04786          0.2254   \n",
              "106          0.28730               0.12180          0.2806   \n",
              "270          0.03866               0.03333          0.2458   \n",
              "435          0.40690               0.18270          0.3179   \n",
              "102          0.11450               0.07431          0.2694   \n",
              "\n",
              "     worst fractal dimension  \n",
              "68                   0.11750  \n",
              "181                  0.12840  \n",
              "63                   0.08490  \n",
              "248                  0.08147  \n",
              "60                   0.08020  \n",
              "..                       ...  \n",
              "71                   0.10840  \n",
              "106                  0.09097  \n",
              "270                  0.06120  \n",
              "435                  0.10550  \n",
              "102                  0.06878  \n",
              "\n",
              "[455 rows x 21 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "selector = RFECV(model, step=1, cv=5, scoring=scorer)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "selected_features = X_train.columns[selector.support_]\n",
        "X_train[selected_features]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "goit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
